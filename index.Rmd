---
title: "Visualization and analysis of probability <br> distributions of large <br> temporal data"
type: "contributed"
author: "<br> Sayani Gupta <br> <hr> &nbsp; Prof. Rob J Hyndman &nbsp; &nbsp; Prof. Dianne Cook &nbsp; &nbsp; Dr. Peter Toscas"
date: <font size="5"> Department of Econometrics and Business Statistics <br>  Pre-submission review <br> March 16, 2021
bgimg: "images/bg1.jpg"
output:
  xaringan::moon_reader:
    after_body: ["libs/collapseoutput.js"]
    css:
      - ninjutsu 
      - "assets/animate.css"
      - "assets/monash-logo.css"
      - "assets/monash-brand.css"
      - "assets/monash-fonts.css"
      - "assets/styles.css" # small improvements
      - "assets/custom.css" # add your own CSS here!
      - "timeline.css"
    # [ "libs/myremark.css", "xaringan-themer.css" , "libs/font-awesome/css/fontawesome-all.css"]
    self_contained: false
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
preamble: >
  \usepackage{amsmath, mathtools,amssymb, booktabs,amsthm,todonotes,colortbl}
---


```{r setup, include=FALSE}
library(knitr)
options(htmltools.dir.version = FALSE, tibble.width = 55, tibble.print_min = 4)
opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE, comment = "#>",
  fig.path = 'figure/', cache.path = 'cache/', fig.align = 'center', 
  fig.width = 12, fig.show = 'hold', fig.height = 7, # 16:9
  cache = TRUE, external = TRUE, dev = 'svglite',
  results = "markup"
)
read_chunk('R/theme.R')
read_chunk('R/main.R')
```

```{r xaringan-themer, include = FALSE, eval=FALSE}
library(xaringanthemer)
 solarized_dark(
   header_font_google = google_font("Josefin Sans"),
   text_font_google   = google_font("Montserrat", "300", "300i"),
   code_font_google   = google_font("Droid Mono"),
   # header_color = "#00aba9",
   # text_color = "#2b5797"
   # # header_color = "#00008B",
   # text_color = "#8B4513"
  header_color = "#ffbb33",
  # text_color = "#FFDAB9",
  text_color = "White",
  background_color = "#555555",
  #title_slide_background_color = " #D9D690"
 )
```


# Motivation: Electricity smart meter data

### Electricity smart meter technology <br> (~ 0.3 billion half hourly observations)

- Source: Department of the Environment and Energy, Australia
<br>
<br>
- Frequency:  Half hourly (interval meter reading (Kwh))
<br>
<br>
- Time Span: 2012 to 2014
<br>
<br>
- Spread: 14K (approx.) households based in Newcastle, New South Wales, and parts of Sydney
<br>
<br>

---

```{r load-elec, message = FALSE, warning=FALSE}
```

# Characteristics of the data

.left-column[
- missing observations
- unequal length
- different start and end date
- no behavioral pattern visible in the squeezed linear representation
- many households
]


.right-column[
```{r elec-raw}

```
]

---
class:top, center

# Understanding behavioral pattern

```{r elec-cyclic, eval=FALSE}
a
```



---
class:top, center

# Theme of research

```{r load-theme}
```


---

# Literature review



---

class:left, top

#  Projects 

.larger[
- Visualize probability distributions over different time granularities <br><br>
- Clustering temporal data based on <br> probability distributions <br><br>
- Study of Australian smart meter data
]
---
class: middle center

<!-- SLIDE 4 -->

.animated.bounce[
<img src="images/gravitas_sticker.png" height=280px>
]

## Visualizing probability distributions across bivariate cyclic temporal granularities



---

# Main contributions

    * provide a formal characterization of cyclic granularities;
    * facilitate manipulation of single- and multiple-order-up time granularities through cyclic calendar algebra;
    * develop an approach to check the feasibility of creating plots or drawing inferences for any two cyclic granularities.

---

class: top left 

# Linear to cyclic

.pull-left[
.checked[
.smaller[
- **Cyclic time granularities:** exploring different periodicities e.g. hour-of-day, day-of-month or  hour-of-week, day-of-semester

- **Multiple observations for each level of cyclic granularity**

- summarize distribution of measured variables
]
]
]

---
class: top left 

# Summarize distribution

.pull-left[
.checked[
.smaller[
- **Cyclic time granularities:** exploring different periodicities e.g. hour-of-day, day-of-month or  hour-of-week, day-of-semester

- Multiple observations for each level of cyclic granularity

- **summarize distribution of measured variables**
]
]
]

.pull-right[
```{r allplot, animation.hook="gifski"}

```
]

.pull-right[
```{r linear2cyclic, animation.hook="gifski"}
```
]
---

class: top left

# Data structure and graphical mapping

.left-column[
<br>
<br>
-  extension of tsibble data structure
-  choose any two cyclic granularities: 
$C_i = \{A_1, A_2, \dots, A_K\}$ and $C_j = \{B_1, B_2, \dots, B_L\}$
- graphical mapping $(C_i, C_j, v)$

- $^{N_C}P_2$ displays
]

.right-column[

```{r graphical map, out.width="90%"}

```

]
---
class:left, top

# Relationship of cyclic granularities

.pull-left[
**<span style="color:firebrick"> <i> Clashes</i>:** pairs leading to empty sets

```{r clash, out.width="100%"}
```

]

.pull-right[
**<span style="color:firebrick"> <i> Harmonies</i>:** pairs leading to no empty sets



```{r noclash, out.width="100%"}
```
]

Still too many harmonies for display for large $N_C$
---



---

# Cyclic calendar algebra


- from single to multiple order-up 
<br> .smaller[e.g. day-of-semester from day-of-month]
- from  multiple to single order-up
<br> .smaller[e.g. hour-of-day from hour-of-week]
---
class:center, top

---

# Application: Non-temporal case
.left-column[
## Cricket example
.checked[
* data structure
<br>
<br>
* Hierachy table
```{r hierarchy2}
```
]
]
.right-column[
```{r cricket-glimpse}
knitr::include_graphics("images/cricket_data.png")
```
]
---

<!-- SLIDE 9 -->
.left-column[
## Cricket example
.checked[
* data structure
* search granularities `search_gran()`
]
]
.right-column[

```r
cricket_tsibble <- cricket %>%
*  mutate(data_index = row_number()) %>%
*  as_tsibble(index = data_index)
```

```r
* cricket_tsibble %>%
*  search_gran(hierarchy_model, 
*              lowest_unit = "ball",
*               highest_unit =  "match")
```
.pull-left[
```{r search_gran_cric}
```
]
.pull-right[
<br>
<br>
.smaller[
- There are $^{6} P_2$ =  `r length(combn(6,2))` pair of granularities to look at
- 30 visualizations to interpret?
]
]
]
---

.left-column[
## Cricket example
.checked[
* data structure
* search granularities `search_gran()`
* set of harmonies `harmony()`
]
]
.right-column[
```r
cricket_tsibble %>%
*  harmony(hierarchy_model, 
*          lgran = "ball",
*          ugran =  "match")

```

```{r harmony_gran_cric}
```
.smaller[
- only 8 out `r length(combn(6,2))` are harmonies<br>
- plotting other 22 pairs lead to empty combinations
]
]
---

.left-column[
## Cricket example
.checked[
* data structure
* search granularities `search_gran()`
* set of harmonies `harmony()`
* advice `gran_advice()`
]
]
.right-column[

```r
cricket_tsibble %>% 
*  gran_advice("hierarchy_model",
*              "over_inning", 
*              "inning_match")
```
<small>
```{r gran-advice_cric, out.width="100%"}
```
</small>
### <large>  Quantile plots recommended for the harmony pair (over_inning, inning_match) </large>
]
---
.left-column[
## Cricket example
.checked[
* data structure
* search granularities `search_gran()`
* set of harmonies `harmony()`
* advice `gran_advice()`
* visualize harmonies `prob_plot()`
]
]
.right-column[
```r
cricket_tsibble %>% 
filter(batting_team %in% c("Mumbai Indians",
                           "Chennai Super Kings")) %>%
* prob_plot("inning_match",
*            "over_inning",
*            response = "runs_per_over",
*            hierarchy_model,
*            plot_type = "lv")
```

```{r visualise_cric}
```
]
---
# Aperiodic cyclic granularities in cricket
```{r aperiodic_cric, fig.height = 7.5}
```
---

# Project 2: Title slide


---

# Project 2: Contributions

 - introduce a new distance measure for quantifying periodic interactions, which allows for identification of patterns in the time series data;
 - device a framework for choosing a threshold, which results in detection of only significantly interesting periodic patterns;
 - show that the proposed distance metric could be used to rank the periodic patterns based on how well they capture the variation in the measured variable since they have been normalized for relevant parameters.

---


# Project 2: Idea

.pull-left[
```{r example-design}
```
]

.pull-right[
<br>
- Rank harmonies $a (D_{null}) < b (D_{var_f})$  
$<  c(D_{var_x}) < d(D_{var_{all}})$
- Gestalt theory
- within and between facet variation/distances
- compute a threshold
]

---

# Project 2: Notations
```{r dist-explain}
```

<small>
- two cyclic granularities $A$ and $B$ placed across x-axis and facet respectively. 
- $A = \{ a_j: j = 1, 2, \dots, J\}$ and $B = \{ b_k: k = 1, 2, \dots, K\}$
- within-facet distances $(a_{j}b_{k}, a_{j'}b_{k})$
- between-facet distances $(a_{j}b_{k}, a_{j}b_{k'})$

---
# Project 2: Computation

- NQT performed
-  Percentiles of $v^*_{jk}$ are computed and stored in $q_{jk}$.
- The pairwise distances between pairs $(a_{j} b_{k}, a_{j'}b_{k'})$  denoted by $d_{(jk, j'k')} = JSD(q_{jk}, q_{j'k'})$ is computed.
- The pairwise distances $d_{(jk, j'k')}$ is transformed using a suitable tuning parameter $0<\lambda<1$ depending on if they are within-facet $d_w$ or between-facets $d_b$ as follows:  

.smaller[
\begin{align}
d*_{(j,k), (j'k')} &= \lambda d_{(jk), (j'k')}, d = d_w \\
             &= (1-\lambda)  d_{(jk), (j'k')}, d = d_b
\end{align}
]

---
class:left, top

# Clustering temporal data based on <br> probability distributions

## Assumptions

.smaller[
- $C_1: \mathbb{Z}_+ \mapsto \{L_1, L_2, L_3, \dots, L_m \}$
- $C_2: \mathbb{Z}_+ \mapsto \{L_1, L_2, L_3, \dots, L_p \}$
- $S(i, j, k)$: set of measurement variables corresponding to the key $i$ for $k^{th}$ level of $C_1$ and $j^{th}$ level of $C_2$
- $P(i, j, k)$: probability distribution of the measured variable corresponding to the set $S(i, j, k)$
- each observational unit $i$ will have $mp$ variables each of which is a probability distribution
- clustering algorithm on these $P(i, j, k)$ instead of raw data
]
---
class:left, top

# Clustering temporal data based on <br> probability distributions

## Implications
- Dimension reduction
- Robust to outliers by trimming the tails
- Non-synchronized observed time periods
- Similar periodic behavior
- Handling autocorrelation


---
class:left, top

# Study of Australian smart meter data

.smaller[
* Provide preliminary exploratory visualization and summarisation
* Employ cluster analysis to obtain households showing similar periodic behavior and combine the findings with external data like weather conditions, socio-economic or other demographic factors of those households
* Comparative study with earlier methods which focused on clustering raw data across linear time scales as opposed to clustering probability distributions across periodic scales
]
---

.left-column[
## Timeline
### - 2019
]
.right-column[
.timeline.timeline-left.timeline-with-arrows[
.timeline-block[

.timeline-block[
.arrow-right[
.timeline-content[
Internship with Google Summer of Code
.timeline-date[
2019/08
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
Young Statistician's Conference -  
won the 2nd best presentation award `r emo::ji("trophy")`
.timeline-date[
2019/10
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
R package `gravitas` on CRAN
.timeline-date[
2019/11
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
R package `gghdr`: graphing highest density regions at [rOpenSci](https://ropensci.org/) 
.timeline-date[
2019/12
]]]]


.timeline-block[
.arrow-right[
.timeline-content[
International Indian Statistical Association 
.timeline-date[
2019/12
]]]]

]
]
]

---

.left-column[
## Timeline
### - 2019
### - 2020
]
.right-column[
.timeline.timeline-left.purple-flirt.timeline-with-arrows[


.timeline-block[
.arrow-right[
.timeline-content[
Mid-Candidature Review
.timeline-date[
2020/03
]]]]


.timeline-block[
.arrow-right[
.timeline-content[
R package `gghdr` to be submitted on CRAN 
.timeline-date[
2020/03
]]]]


.timeline-block[
.arrow-right[
.timeline-content[
Paper to be submitted to Journal of Computational and Graphical Statistics (JCGS)
.timeline-date[
2020/04
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
useR! 2020 (Tentative)
.timeline-date[
2020/07
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
Compstat 2020 (Tentative)
.timeline-date[
2020/08
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
R package and draft paper of Research objective-2 ready
.timeline-date[
2020/10
]]]]
]
]

---

.left-column[
## Timeline
### - 2019
### - 2020
### - 2021
]

.right-column[
.timeline.timeline-left.purple-flirt.timeline-with-arrows[

.timeline-block[
.arrow-right[
.timeline-content[
Pre-submission Review 
.timeline-date[
2021/03
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
Research objective-3 draft paper ready 
.timeline-date[
2021/03
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
Thesis submission `r emo::ji("v")`
.timeline-date[
2021/06
]]]]
]
]
---
class: center middle 

# Thank you

<br>
## Joint work with Rob J Hyndman & Dianne Cook
<br>
<br>
### <span style="color:black"> Special thanks to NUMBATS
<br>
<br>


.footnote[
Slides created with <i> Rmarkdown, knitr, xaringan, xaringanthemer</i>
]
---


```{r leveltable}

```

.smaller[
.smaller[
low: less than 7 (days in a week), medium: between 7 and 14 (days in a fortnight), high: between 14 and 31 (days in a month), very high: higher than 31
]
]


# Clustering: Missing value analysis

```{r elec-gaps, warning=FALSE}
```

.right-column[
```{r count-gaps, fig.height = 8, fig.cap="The missing data pattern for 100 households are shown. It looks like most missingness happens before 2013 and for a particular data in 2014."}

```
]


---


```{r load}
```


```{r motivation3, out.height="500px"}
```

